scrape_configs:
    - job_name: "prometheus"
      static_configs:
          - targets:
                - "localhost:9091"
      basic_auth:
          username: "{{ pillar.monitor.prometheus.web.username }}"
          password: "{{ pillar.monitor.prometheus.web.password }}"

    - job_name: "aws-ec2"
      ec2_sd_configs:
          - region: us-east-1
            access_key: "{{ pillar.monitor.prometheus.ec2_sd_configs.access_key }}"
            secret_key: "{{ pillar.monitor.prometheus.ec2_sd_configs.secret_key }}"
            port: 9100
      relabel_configs:
          - source_labels: ["__meta_ec2_tag_Name"] # annotations--continuumtest--1
            target_label: "ec2_name"
          - source_labels: ["__meta_ec2_tag_Project"] # annotations
            target_label: "ec2_project"
          - source_labels: ["__meta_ec2_tag_Environment"] # continuumtest
            target_label: "ec2_env"
          - source_labels: ["__meta_ec2_tag_Node"] # 1
            target_label: "ec2_node"
          - source_labels: ["__meta_ec2_tag_Cluster"] # annotations--continuumtest
            target_label: "ec2_cluster"
      # also: instance type (t3.medium), instance state (stopped, running), availability zone (us-east-1d), region (us-east-1), ami, ...

    - job_name: "yace"
      static_configs:
        - targets:
            - "localhost:9097"

rule_files:
    - /etc/prometheus.rules-config.yml

alerting:
    alertmanagers:
        - static_configs:
              - targets:
                    - localhost:9095
          basic_auth:
              username: "{{ pillar.monitor.prometheus.web.username }}"
              password: "{{ pillar.monitor.prometheus.web.password }}"

