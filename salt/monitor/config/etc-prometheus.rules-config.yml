# https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/
# https://github.com/samber/awesome-prometheus-alerts/tree/master

groups:
{% if pillar.monitor.healthcheck_list %}
    - name: "health checks" # previously 'synthetics'
      rules:
{% for healthcheck in pillar.monitor.healthcheck_list %}
        - alert: "{{ healthcheck.label }}"
          expr: aws_route53_health_check_percentage_healthy_average{dimension_health_check_id="{{ healthcheck.id }}"} < 90
          for: {{ healthcheck.duration }}
          labels:
              severity: critical
          annotations:
              summary: "{{ healthcheck.description }}"
{% endfor %}
{% endif %}
{% raw %}
    - name: "infrastructure"
      rules:
          - alert: HostNotReporting # if you change this alert name also update AlertManager routing rules
            expr: up == 0
            for: 5m
            labels:
                severity: critical
            annotations:
                summary: "A host is not reporting: {{ $labels.ec2_name }}"

          # ---

          - alert: DiskUsageHigh
            expr: (100 - ((node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes)) > 70
            for: 20m
            labels:
                severity: warning
            annotations:
                # "Disk usage ('/') over 70%: lax--prod--3"
                summary: "Disk usage ('{{ $labels.mountpoint }}') over 70%: {{ $labels.ec2_name }}"

          - alert: DiskUsageHigh
            expr: (100 - ((node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes)) > 80
            for: 20m
            labels:
                severity: critical
            annotations:
                # "Disk usage ('/ext') over 80%: lax--prod--3"
                summary: "Disk usage ('{{ $labels.mountpoint }}') over 80%: {{ $labels.ec2_name }}"

          # ---

          - alert: CPUUsageHigh
            expr: (100 - (avg by(ec2_name) (rate(node_cpu_seconds_total{mode="idle"}[2m])) * 100)) > 70
            for: 10m
            labels:
                severity: warning
            annotations:
                summary: "CPU usage over 70% for 10mins: {{ $labels.ec2_name }}"

          - alert: CPUUsageHigh
            expr: (100 - (avg by(ec2_name) (rate(node_cpu_seconds_total{mode="idle"}[2m])) * 100)) > 80
            for: 15m
            labels:
                severity: critical
            annotations:
                summary: "CPU usage over 80% for 15mins: {{ $labels.ec2_name }}"

          # --- cpu < 30% for 30mins. Is this rule correct?

          - alert: CPUUsageSuspiciouslyLow
            expr: (rate(node_cpu_seconds_total{project_instance=~"iiif--prod|journal--prod|lax--prod",mode="idle"}[30m]) * 100) < 30
            for: 30m
            labels:
                severity: warning
            annotations:
                summary: "CPU usage suspiciously low for 30mins: {{ $labels.ec2_name }}"

          # ---

          - alert: MemoryUsageHigh
            expr: (100 - (node_memory_MemAvailable_bytes * 100) / node_memory_MemTotal_bytes) > 70
            for: 10m
            labels:
                severity: warning
            annotations:
                summary: "Memory usage over 70% for 10mins: {{ $labels.ec2_name }}"

          - alert: MemoryUsageHigh
            expr: (100 - (node_memory_MemAvailable_bytes * 100) / node_memory_MemTotal_bytes) > 90
            for: 5m
            labels:
                severity: critical
            annotations:
                summary: "Memory usage over 90% for 5mins: {{ $labels.ec2_name }}"

          # ---

          - alert: CPUStealHigh
            expr: sum by (ec2_name, cpu) (rate(node_cpu_seconds_total{mode="steal"} [2m])) > 20
            for: 10m
            labels:
                severity: critical
            annotations:
                summary: "CPU steal amount over 20% for 10mins: {{ $labels.ec2_name }}"

          # --- sustained elevated disk I/O

          - alert: DiskIOHigh
            expr: rate(node_disk_io_time_weighted_seconds_total[2m]) > 0.5
            for: 20m
            labels:
                severity: warning
            annotations:
                summary: "Disk I/O over 50% for 20mins: {{ $labels.ec2_name }}"

          - alert: DiskIOHigh
            expr: rate(node_disk_io_time_weighted_seconds_total[2m]) > 0.8
            for: 10m
            labels:
                severity: critical
            annotations:
                summary: "Disk I/O over 80% for 10mins: {{ $labels.ec2_name }}"

          # ---

          - alert: SwapUsageHigh
            expr: ((1 - (node_memory_SwapFree_bytes / node_memory_SwapTotal_bytes)) * 100) > 70
            for: 10m
            labels:
                severity: warning
            annotations:
                summary: "Swap usage over 70% for 10m: {{ $labels.ec2_name }}"

          - alert: SwapUsageHigh
            expr: ((1 - (node_memory_SwapFree_bytes / node_memory_SwapTotal_bytes)) * 100) > 80
            for: 5m
            labels:
                severity: critical
            annotations:
                summary: "Swap usage over 80% for 5m: {{ $labels.ec2_name }}"

    - name: "new/experimental"
      rules:
          # https://grafana.com/blog/2021/04/01/you-should-know-about...-these-useful-prometheus-alerting-rules/#alerts-for-use-and-red
          # Please add ignored mount points in node_exporter parameters like
          # "--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|run)($|/)".
          # Same rule using "node_filesystem_free_bytes" will fire when disk fills for non-root users.
          - alert: HostDiskWillFillIn24Hours
            expr: (node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10 and ON (ec2_name, device, mountpoint) predict_linear(node_filesystem_avail_bytes{fstype!~"tmpfs"}[1h], 24 * 3600) < 0 and ON (ec2_name, device, mountpoint) node_filesystem_readonly == 0
            for: 2m
            labels:
                type: experimental
                severity: warning
            annotations:
                summary: Host disk will fill in 24 hours (instance {{ $labels.ec2_name }})
                description: "Filesystem predicted to run out of space within the next 24 hours at current write rate\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

          - alert: HostInstanceStatusCheckFailed
            expr: (aws_ec2_status_check_failed_instance_maximum + on (name) group_left(tag_name) aws_ec2_info) > 0
            for: 2m
            labels:
                type: experimental
                severity: critical
            annotations:
                summary: Host has failed one or more instance status checks. A restart is required.
                context: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-system-instance-status-check.html#system-status-checks

          - alert: HostSystemStatusCheckFailed
            expr: (aws_ec2_status_check_failed_system_maximum + on (name) group_left(tag_name) aws_ec2_info) > 0
            for: 2m
            labels:
                type: experimental
                severity: critical
            annotations:
                summary: Host has failed a system status check. A restart would probably solve this.
                context: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-system-instance-status-check.html#instance-status-checks

          # ELB
          - alert: ELB UnhealthyNodes
            expr: (aws_elb_un_healthy_host_count_maximum + on (name) group_left(tag_name) aws_elb_info{tag_environment="prod"}) > 0
            for: 5m
            labels:
                type: experimental
                severity: critical
            annotations:
                summary: One or more nodes in a load balancer is unhealthy. Unhealthy nodes are removed if they fail multiple health checks.
                context: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-system-instance-status-check.html#instance-status-checks

          - alert: ELB ErrorPercentHigh
            expr: (aws_elb_httpcode_backend_5_xx_sum / aws_elb_request_count_sum + on (name) group_left(tag_name) aws_elb_info) * 100 > 5
            for: 5m
            labels:
                type: experimental
                severity: critical
            annotations:
                summary: "The number of errors returned by the (classic) load balancer '{{ $labels.tag_name }}' is high (>5%)"

          # ALB
          - alert: ALB UnhealthyNodes
            expr: (aws_applicationelb_un_healthy_host_count_maximum + on (name) group_left(tag_name) aws_elb_info{tag_environment="prod"}) > 0
            for: 5m
            labels:
                alert_type: experimental
                severity: critical
            annotations:
                summary: One or more nodes in a load balancer is unhealthy. Unhealthy nodes are removed if they fail multiple health checks.
                context: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-system-instance-status-check.html#instance-status-checks

          - alert: ALB ErrorPercentHigh
            expr: (aws_applicationelb_httpcode_target_5_xx_count_sum / aws_applicationelb_request_count_sum + on (name) group_left(tag_name) aws_applicationelb_info) * 100 > 5
            for: 5m
            labels:
                type: experimental
                severity: critical
            annotations:
                summary: "The number of errors returned by the (application) load balancer '{{ $labels.tag_name }}' is high (>5%)"

          # SES
          - alert: SESBouncedEmail
            expr: aws_ses_bounce_sum > 0
            for: 5m
            labels:
                alert_type: experimental
                severity: warning
            annotations:
                summary: SES email has bounced.

          # todo: needs work
          - alert: SESBounceRateHigh
            expr: aws_ses_reputation_bounce_rate_sum > 7.5
            for: 5m
            labels:
                alert_type: experimental
                severity: critical
            annotations:
                summary: SES emails has bounced.

          - alert: SESComplaintRateHigh
            expr: aws_ses_reputation_complaint_rate_sum > 0
            for: 5m
            labels:
                alert_type: experimental
                severity: critical
            annotations:
                summary: SES email has received a complaint.

          - alert: SESDailySendCountHigh
            expr: aws_ses_send_sum > 1000 # 50% of 2000, our daily limit
            for: 5m
            labels:
                alert_type: experimental
                severity: warning
            annotations:
                summary: SES emails has bounced.

          - alert: SESDailySendCountHigh
            expr: aws_ses_send_sum > 1500 # 75% of 2000, our daily limit
            for: 5m
            labels:
                alert_type: experimental
                severity: critical
            annotations:
                summary: SES emails has bounced.

          # RDS

          - alert: RDS Storage Low
            expr: ((aws_rds_free_storage_space_minimum / 1024) / 1024) + on (name) group_left (tag_name) aws_rds_info < 2000
            for: 2h
            labels:
                severity: warning
            annotations:
                summary: "Disk space on RDS instance has been less than 2GiB for 2hrs: {{ $labels.tag_name }}"
                description: "A 2GiB buffer is safe for most databases. Less than this for a long period and it may need to be increased."

          - alert: RDS Storage Low
            expr: ((aws_rds_free_storage_space_minimum / 1024) / 1024) + on (name) group_left (tag_name) aws_rds_info < 2000
            for: 12h
            labels:
                severity: critical
            annotations:
                summary: "Disk space on RDS instance has been less than 2GiB for 12hrs: {{ $labels.tag_name }}"
                description: "The size of the disk probably needs to be increased."

          - alert: RDS Connections Low in Prod
            expr: aws_rds_database_connections_maximum + on (name) group_left(tag_name) aws_rds_info{tag_environment="prod",tag_name!~"elife-dashboard--prod|digests--prod"} < 1
            for: 10m
            labels:
                severity: warning
            annotations:
                summary: "The number of database connections have been suspiciously low for 10mins: {{ $labels.tag_name }}"
                description: "This may indicate the database, application or host(s) are down."

          - alert: RDS Memory Low
            expr: ((aws_rds_freeable_memory_average / 1024) / 1024) + on (name) group_left (tag_name) aws_rds_info{tag_environment="prod"} < 100
            for: 30m
            labels:
                severity: warning
            annotations:
                summary: "The amount of freeable memory has been less than 100MB for 30m: {{ $labels.tag_name }}"
                description: "The database is under sustained load. The workload or instance type may need to change."

          - alert: RDS Memory Low
            expr: ((aws_rds_freeable_memory_average / 1024) / 1024) + on (name) group_left (tag_name) aws_rds_info{tag_environment="prod"} < 100
            for: 1h
            labels:
                severity: critical
            annotations:
                summary: "The amount of freeable memory has been less than 100MB for 1hr: {{ $labels.tag_name }}"
                description: "The database is under sustained load. The workload or instance type needs to change."

{% endraw %}
